{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmed-boutar/interpreting-rule-based-models/blob/main/interpreting_rule_based_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Google Colab notebook uses the imodels library to interpret these rule-based models:\n",
        "- OneR rule list (oneR)\n",
        "- Slipper rule set (SLIPPER)\n",
        "- Optimal rule list (CORELS) \n",
        "<br>\n",
        "\n",
        "Source: https://github.com/csinva/imodels\n",
        "<br>\n",
        "\n",
        "Details on how these models work can be found in the slides included in the repo under Interpreting-Decision-Rules.pptx\n",
        "<br>\n",
        "\n",
        "One thing I definitely found interesting is that downgrading the version of imodels and scikit-learn influences the accuracy, precicison, and recall of each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Please use this to connect your GitHub repository to your Google Colab notebook\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"interpreting-rule-based-models\" # Change to your repo name\n",
        "git_path = 'https://github.com/ahmed-boutar/interpreting-rule-based-models.git' #Change to your path\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "%cd \"{repo_name}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "!pip install -r requirements.txt #Add if using requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Install corels explicitely to allow OptimalRuleListClassifier to use the Corels algorithm\n",
        "!pip install corels --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running the previous cell, restart the Colab session and run everything except for the first cell to avoid cloning the repo twice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "4YlJecHsLzPb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from graphviz import Digraph\n",
        "\n",
        "from imodels import OptimalRuleListClassifier, SlipperClassifier, OneRClassifier\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset I will be using to train the model is the breast cancer dataset, provided in the scikit-learn library. The dataset titled, Breast Cancer Wisconsin (Diagnostic), is a popular dataset in machine learning, particularly for binary classification tasks. In this case, the target feature is whether or not the cancer tumor is benign or malignant. <br>\n",
        "(Source: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)\n",
        "\n",
        "#### Provenance \n",
        "\n",
        "This dataset contains features computed from digitized images of samples of breast mass tissue. The dataset is used to predict whether a breast tumor is malignant or benign based on various characteristics of the cell nuclei present in the images. \n",
        "\n",
        "#### Authors & License \n",
        "\n",
        "The Breast Cancer Wisconsin (Diagnostic) dataset is part of scikit-learn, which is distributed under the *BSD 3-Clause license*, allowing it to be freely used for academic, commercial, and personal projects (provided the original copyright notice and the BSD 3-Clause license text are included)\n",
        "\n",
        "The dataset was created by Dr. William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian at the University of Wisconsin\n",
        "\n",
        "#### Overview \n",
        "The dataset includes 30 features (all numerical) such as radius, texture, perimeter, area of each cell's nucleus. These features are computed for each cell nucleus, and the mean, standard error, and \"worst\" (largest) values are calculated for each feature.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "breast_cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
        "# Add the target variable, where 1 is benign and 0 is malignant\n",
        "df['diagnosis'] = breast_cancer.target\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df['diagnosis'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All of the models used here for the classification of the breast cancer diagnosis are provided through the imodels library. (Souce: https://github.com/csinva/imodels?tab=readme-ov-file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One R "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This algorithm is often used as a benchmark for other methods. It is considered one of the simplest rule-based classification algorithms. \n",
        "\n",
        "From all the features, one R selects the one that carries the most information about the outcome of interest and creates decision rules from this feature (based on a **single feature**)\n",
        "\n",
        "Source: https://csinva.io/imodels/rule_list/one_r.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "oneR_model = OneRClassifier()\n",
        "oneR_model.fit(X_train, y_train, feature_names=breast_cancer.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = oneR_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(f'Accuracy: {acc:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimal Rule List (CORELS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " This algorithm aims to generate optimal rule lists. Unlike OneR, which focuses on a single feature, CORELS considers multiple features and aims to produce the most interpretable and accurate rule list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://csinva.io/imodels/rule_list/corels_wrapper.html#imodels.rule_list.corels_wrapper.OptimalRuleListClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_rule_list_model = OptimalRuleListClassifier()\n",
        "optimal_rule_list_model.fit(X_train, y_train, feature_names=breast_cancer.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = optimal_rule_list_model.predict(X_test)\n",
        "# Evaluate the model\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(f'Accuracy: {acc:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SLIPPER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SLIPPER is designed to generate decision rule sets for binary classification. It constructs a set of simple rules that work together to classify new observations. It is a **boosting-based rule-learning algorithm**. \n",
        "\n",
        "The boosting process involves a loop that generates simple rules, selecting the best rule based on **weighted error** of each rule, and updated the weights of misclassified observations (increasing their weights, while decreasing the weight of correctly classified observations). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source: https://csinva.io/imodels/rule_set/slipper.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "slipper_model = SlipperClassifier()\n",
        "slipper_model.fit(X_train, y_train, feature_names=breast_cancer.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = slipper_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(f'Accuracy: {acc:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating graphs to visualize the models' outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Used a combination of this documentation https://networkx.org/documentation/stable/reference/classes/digraph.html\n",
        "# And some help from Claude to figure out the correct way to create the graph\n",
        "def create_rule_graph(model_name, model):\n",
        "    # Create a new directed graph\n",
        "    graph = Digraph(comment=f'Decision Rule Visualization for {model_name}')\n",
        "    graph.attr(rankdir='TB', size='8,8')\n",
        "\n",
        "    rules = model.rules_\n",
        "    \n",
        "    # Add nodes and edges based on the rules\n",
        "    for i, rule in enumerate(rules):\n",
        "        node_id = f\"node_{i}\"\n",
        "        try:\n",
        "            # Added this exception to work around the default rule as the format made it harder to include \n",
        "            # in the Digraph\n",
        "            graph.node(node_id, f\"{rule['col']}\\nâ‰¤ {rule['cutoff']:.5f}\")\n",
        "        except KeyError:\n",
        "            break\n",
        "\n",
        "        \n",
        "        # Add left (False) branch\n",
        "        left_id = f\"leaf_{i}_left\"\n",
        "        graph.node(left_id, f\"Value: {rule['val']:.4f}\\nPoints: {rule['num_pts'] - rule['num_pts_right']}\")\n",
        "        graph.edge(node_id, left_id, label='False')\n",
        "        \n",
        "        # Add right (True) branch\n",
        "        right_id = f\"leaf_{i}_right\"\n",
        "        graph.node(right_id, f\"Value: {rule['val_right']:.4f}\\nPoints: {rule['num_pts_right']}\")\n",
        "        graph.edge(node_id, right_id, label='True')\n",
        "        \n",
        "        # Connect to the next rule if it exists\n",
        "        if i < len(rules) - 1:\n",
        "            graph.edge(left_id, f\"node_{i+1}\", style='dashed')\n",
        "\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to save the graph as a dot file to display \n",
        "# Used this website https://www.devtoolsdaily.com/graphviz/ to visualize the outputs \n",
        "# Just copy pasted the output of the .dot file into the visualization website\n",
        "def save_graph(dot, filename, format='pdf', graphviz_path=None):\n",
        "    if graphviz_path:\n",
        "        dot.engine = os.path.join(graphviz_path, 'dot')\n",
        "    \n",
        "    dot.save(f'{filename}.dot')\n",
        "    print(f\"DOT file saved as '{filename}.dot'\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to save the graph\n",
        "oneR_graph = create_rule_graph('One R', oneR_model)\n",
        "save_graph(oneR_graph, 'oneR_box_diagram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_rule_list_graph= create_rule_graph('Corels', optimal_rule_list_model)\n",
        "save_graph(optimal_rule_list_graph, 'CORELS_diagram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dot = Digraph(comment='Slipper Model Decision Tree')\n",
        "dot.attr(rankdir='TB', size='12,12')\n",
        "rules = slipper_model.rules_\n",
        "formatted_rules = []\n",
        "#format the numbers in the rules to have 3 digits after the decimal\n",
        "for i, rule in enumerate(rules):\n",
        "    split_rule = rule.rule.split(' ')\n",
        "    for i in range(len(split_rule)):\n",
        "        try:\n",
        "            tmp = '%.3f'%(float(split_rule[i]))\n",
        "            #print(tmp)\n",
        "            split_rule[i] = str(tmp)\n",
        "            \n",
        "        except ValueError:\n",
        "            continue\n",
        "    formatted_rules.append(' '.join(split_rule))\n",
        "\n",
        "print(formatted_rules)\n",
        "\n",
        "# Followed almost exact same visualization code as above to create the graph \n",
        "# Had to do it separately here since the output of the SLIPPER model is a decision rule set, which is different than the other models\n",
        "# Add nodes and edges based on the rules\n",
        "for i, rule in enumerate(formatted_rules):\n",
        "    node_id = f\"rule_{i}\"\n",
        "    dot.node(node_id, f\"Rule {i+1}\\n{rule}\", shape='box')\n",
        "    \n",
        "    # Add Yes/No branches\n",
        "    yes_id = f\"yes_{i}\"\n",
        "    no_id = f\"no_{i}\"\n",
        "    dot.node(yes_id, \"Yes\", shape='ellipse')\n",
        "    dot.node(no_id, \"No\", shape='ellipse')\n",
        "    dot.edge(node_id, yes_id, label='True')\n",
        "    dot.edge(node_id, no_id, label='False')\n",
        "    \n",
        "    # Connect 'No' to the next rule if it's not the last rule\n",
        "    if i < len(rules) - 1:\n",
        "        dot.edge(no_id, f\"rule_{i+1}\", style='dashed')\n",
        "\n",
        "save_graph(dot, 'SLIPPER')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOMR1VL2dmBg8lSRAL97qXj",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
